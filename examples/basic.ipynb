{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/steering_research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x10650e470>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sae_lens import SAE\n",
    "# from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "# from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import normalise_decoder\n",
    "from steering.patch import generate, scores_2d\n",
    "\n",
    "# from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "# import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp6 = \"blocks.6.hook_resid_post\"\n",
    "\n",
    "sae6, _, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = hp6, # won't always be a hook point\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "sae6 = sae6.to(device)\n",
    "normalise_decoder(sae6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligence = sae6.W_dec[10351]   # intelligence and genius\n",
    "writing = sae6.W_dec[1058]  # writing\n",
    "anger = sae6.W_dec[1062]  # anger\n",
    "london = sae6.W_dec[10138]  # London\n",
    "wedding = sae6.W_dec[8406]  # wedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def patch_resid(resid, hook, steering, scale=1, some_text=\"\"):\n",
    "#     print(some_text)\n",
    "#     resid[:, :, :] = resid[:, :, :] + steering * scale\n",
    "#     return resid\n",
    "\n",
    "# hooks = [\n",
    "#     (hp6, partial(patch_resid, steering=london, scale=70, some_text=\"London\")),\n",
    "#     (hp6, partial(patch_resid, steering=wedding, scale=70, some_text=\"wedding\")),\n",
    "# ]\n",
    "\n",
    "# generate(model,\n",
    "#         hooks=hooks,\n",
    "#         # schedules=[(1, 15), (16, None)],\n",
    "#         max_new_tokens=35,\n",
    "#         prompt=\"I think\",\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss computation not implemented\n",
      "loss grid\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "evaluating (0, 0)\n",
      "['I think I would be a little surprised.\\n\\nIf I am ever allowed to go back to normal 50% of my work', 'I think it was the second day that I’d been home and I was out doing some groceries when I suddenly got the worst headache', 'I think I’d say the first word, that’s the main key to it! As your speaking, people will probably be', 'I think it\\'s a 44 magnum. 7.5\" barrel with Hogue rubber grips. It has the adjustable']\n",
      "evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 1.0\n",
      "Mentions wedding or wedding-related things 1.0\n",
      "Text is coherent, the grammar is correct. 8.0\n",
      "evaluating (0, 1)\n",
      "['I think the reason is that you are trying to use a feature (<code>-o</code> ) of the <code>vim</code> command which', 'I think it\\'s pretty obvious the most important one is \"A.\"\\nThat\\'s why I\\'ve decided to host the', 'I think every mother at some time, want this feeling. Those feelings to cherish and treasure your child for a lifetime. To cherish for', 'I think of the perfect man in my head all the time. It always follows with, “he’d have to be tall.”']\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 1.0\n",
      "Mentions wedding or wedding-related things 1.0\n",
      "Text is coherent, the grammar is correct. 8.0\n",
      "evaluating (0, 2)\n",
      "['I think that in today world, there are lots of people who choose to have the same wedding ceremony. That day is a <strong>', \"I think a 20 year old should give away a cake to his best? well.. it's time of the year wedding\", 'I think the wedding party season is coming just when that time is and the night is. wedding decorations.  We can have the wedding', \"I think the name of the wedding is spelled wrong. I don's know if they did it over two years, though. It\"]\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 1.0\n",
      "Mentions wedding or wedding-related things 4.75\n",
      "Text is coherent, the grammar is correct. 5.25\n",
      "evaluating (1, 0)\n",
      "['I think we were all disappointed that the new show went off air after five episodes. But maybe the TV series <em>The Exorcist', 'I think a lot of men know quite well that they have an extra pair of feet, the size of which makes many of the women', 'I think these are perfect for my space in my home. I have a kitchen,diningroom and snug and so they work for all', \"I think both methods are the same.\\nWhen I'm not wearing any of these:\\n\\n* When I'm driving my\"]\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 1.0\n",
      "Mentions wedding or wedding-related things 1.0\n",
      "Text is coherent, the grammar is correct. 6.75\n",
      "evaluating (1, 1)\n",
      "[\"I think its going to give everyone a surprise\\nit's just like the last time they married\\nat that time the royal wedding\", 'I think I found the perfect dress and I have the perfect wedding too, in a wedding the next time, in 201', 'I think it’s important to be honest but here I’m also having these feelings. I’m here on a Wednesday night', 'I think the bride/groom parties are amazing for weddings but are too often overlooked due to a busy schedule. It is becoming more and']\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 2.75\n",
      "Mentions wedding or wedding-related things 6.75\n",
      "Text is coherent, the grammar is correct. 8.0\n",
      "evaluating (1, 2)\n",
      "['I think that, just like wedding. day, 2012 will bring 8. of the year in Italy.\\n\\n', 'I think of a wedding, is so exciting, day,,. The day day is at venue in, London, day.,', 'I think it is going today, and I have an engagement in in the. <strong>B. & Bride,</strong> has been a', 'I think its a good idea, but also an up market. I have been in the industry since 2 at venues all over and']\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 3.25\n",
      "Mentions wedding or wedding-related things 6.25\n",
      "Text is coherent, the grammar is correct. 4.0\n",
      "evaluating (2, 0)\n",
      "['I think it’s fair to say that this guy was inspired by London. He’’s been in town visiting for a couple', 'I think I have found something at this link. It works!!! I put two links, one for women and one man. So!', 'I think that, as a Londoner, I tend to judge a restaurant as a restaurant by its’ food, as well as its', 'I think now I’ll be able to play some of the UK’s biggest music festivals in 2021.\\n\\n']\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 6.25\n",
      "Mentions wedding or wedding-related things 1.0\n",
      "Text is coherent, the grammar is correct. 8.0\n",
      "evaluating (2, 1)\n",
      "['I think, it will start at 2015\\n\\n* I am in London!.\\n\\n\\n21st, -', 'I think i have got a love heart diamond ring 1871. and with is wedding. So so beautiful 😍 with ', 'I think this is only available with two weddings. - Wedding dresses are:, London, York, and. Wedding London. Wedding.', 'I think is is ok\\n\\nJust don,s Town\\n\\nLove This London,s West End\\n\\nI had the most wonderful New Wedding']\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 6.0\n",
      "Mentions wedding or wedding-related things 6.0\n",
      "Text is coherent, the grammar is correct. 2.5\n",
      "evaluating (2, 2)\n",
      "[\"I think that' is my home is in is the day,. London,., by will,,... - My\", 'I think I wedding wedding invitations in \\n\\n\\n, <strong>, wedding, New York</strong> - \\n\\n <strong>.</strong>,', 'I think it was that week.\\n\\nDay... \\n\\n\\n\\n! \\n\\nLondon Wedding?!!!   Wedding London Wedding', 'I think there is a ceremony this weekend but I. but at in or and\\n\\n! in. London! London. to\\n\\n\\n\\n']\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "evaluating\n",
      "done\n",
      "Mentions London or London-related things 6.75\n",
      "Mentions wedding or wedding-related things 5.0\n",
      "Text is coherent, the grammar is correct. 3.5\n"
     ]
    }
   ],
   "source": [
    "score_1, score_2, loss, coherence = scores_2d(\n",
    "    model,\n",
    "    hp6,\n",
    "    steering_vectors=[london, wedding],\n",
    "    prompt=\"I think\", \n",
    "    criterions=[\"Mentions London or London-related things\", \"Mentions wedding or wedding-related things\"],\n",
    "    scales=[0, 40, 80],\n",
    "    max_new_tokens=25,\n",
    "    n_samples=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
