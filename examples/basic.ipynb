{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slava/safety/steering_research/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x105782bc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sae_lens import SAE\n",
    "# from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "# from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import normalise_decoder\n",
    "from steering.patch import generate\n",
    "\n",
    "# from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "# import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Union, Optional, Literal\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import einops\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utilities import devices\n",
    "from transformer_lens.past_key_value_caching import HookedTransformerKeyValueCache\n",
    "import transformer_lens.utils as tutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp6 = \"blocks.6.hook_resid_post\"\n",
    "hp12 = \"blocks.12.hook_resid_post\"\n",
    "\n",
    "sae6, _, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = hp6, # won't always be a hook point\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "sae6 = sae6.to(device)\n",
    "normalise_decoder(sae6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligence = sae6.W_dec[10351]   # intelligence and genius\n",
    "writing = sae6.W_dec[1058]  # writing\n",
    "anger = sae6.W_dec[1062]  # anger\n",
    "london = sae6.W_dec[10138]  # London\n",
    "wedding = sae6.W_dec[8406]  # wedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_resid(resid, hook, steering, scale=1, some_text=\"\"):\n",
    "    print(some_text)\n",
    "    resid[:, :, :] = resid[:, :, :] + steering * scale\n",
    "    return resid\n",
    "\n",
    "hooks = [(\n",
    "    \"blocks.6.hook_resid_post\", \n",
    "    partial(patch_resid, steering=london, scale=70, some_text=\"London\")\n",
    "), \n",
    "(\n",
    "    \"blocks.6.hook_resid_post\", \n",
    "    partial(patch_resid, steering=wedding, scale=70, some_text=\"wedding\")\n",
    ")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "London\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n",
      "wedding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I think there is a bug, if one of the points/stations was in the London area.\\nMaybe the date is a big problem between to guests.\\n\\nHello,\\n\\nyou',\n",
       " 'I think the London is better, I went to the theatre with two friends, as a birthday present to our friend. It was fun but not at all the best night we have ever',\n",
       " \"I think it would be very easy to do a London to Paris marathon, if I wasn't a runner but wedding planner or photographer. As a Londoner, London was on my\",\n",
       " 'I think it could be done in 10 mins. So in 3 years you’ll pay almost $700 for the same service (assuming its still the same).']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model,\n",
    "        hooks=hooks,\n",
    "        schedules=[(1, 15), (16, 30)],\n",
    "        max_length=35,\n",
    "        prompt=\"I think\",\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
