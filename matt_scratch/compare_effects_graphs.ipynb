{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff6ce21d600>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import einops\n",
    "import json\n",
    "\n",
    "from typing import List, Callable, Union, Optional, Literal\n",
    "from collections import defaultdict\n",
    "\n",
    "from sae_lens import SAE\n",
    "# from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "# from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import normalise_decoder, text_to_sae_feats\n",
    "from steering.patch import generate, scores_2d, patch_resid\n",
    "\n",
    "# from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29008/420386180.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g2_forward_indices = torch.load(\"../effects/g2_top_is.pt\", map_location=torch.device(\"cpu\"))\n",
      "/tmp/ipykernel_29008/420386180.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g2_forward_values = torch.load(\"../effects/g2_top_vs.pt\", map_location=torch.device(\"cpu\"))\n",
      "/tmp/ipykernel_29008/420386180.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g_forward_indices = torch.load(\"top_is.pt\", map_location=torch.device(\"cpu\"))\n",
      "/tmp/ipykernel_29008/420386180.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g_forward_values = torch.load(\"top_vs.pt\", map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "g2_forward_indices = torch.load(\"../effects/g2_top_is.pt\", map_location=torch.device(\"cpu\"))\n",
    "g2_forward_values = torch.load(\"../effects/g2_top_vs.pt\", map_location=torch.device(\"cpu\"))\n",
    "\n",
    "g_forward_indices = torch.load(\"top_is.pt\", map_location=torch.device(\"cpu\"))\n",
    "g_forward_values = torch.load(\"top_vs.pt\", map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = g_forward_indices.shape[0]\n",
    "# Create a square adjacency matrix filled with zeros\n",
    "g_adjacency_matrix = torch.zeros((num_features, num_features))\n",
    "\n",
    "for i in range(num_features):\n",
    "    # Get non-zero indices and values\n",
    "    non_zero_mask = g_forward_values[i] != 0\n",
    "    indices = g_forward_indices[i][non_zero_mask]\n",
    "    values = g_forward_values[i][non_zero_mask]\n",
    "    \n",
    "    # Set the values in the adjacency matrix\n",
    "    g_adjacency_matrix[i, indices] = values\n",
    "\n",
    "g2_adjacency_matrix = torch.zeros((num_features, num_features))\n",
    "\n",
    "for i in range(num_features):\n",
    "    non_zero_mask = g2_forward_values[i] != 0\n",
    "    indices = g2_forward_indices[i][non_zero_mask]\n",
    "    values = g2_forward_values[i][non_zero_mask]\n",
    "    \n",
    "    g2_adjacency_matrix[i, indices] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_london = 14455\n",
    "g_london = 10138\n",
    "\n",
    "g2_anger = 4111\n",
    "g_anger = 1062\n",
    "\n",
    "g2_wedding_1 = 4230\n",
    "g2_wedding_2 = 6021\n",
    "g_wedding_1 = 8406\n",
    "g_wedding_2 = 2378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.5479, 0.2494, 0.2442, 0.1779, 0.1537, 0.1027, 0.0998, 0.0996, 0.0986,\n",
      "        0.0951]),\n",
      "indices=tensor([6810, 4354, 7507, 8675, 3928, 8464, 8223, 8645,  847, 3760]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0038, 0.5537, 0.2807, 0.2729, 0.1502, 0.1440, 0.1255, 0.1239, 0.1153,\n",
      "        0.1104]),\n",
      "indices=tensor([10138, 10655,  4343, 12090,  5523, 11444,  9104, 11912, 13568,  7329]))\n"
     ]
    }
   ],
   "source": [
    "print(g2_adjacency_matrix[g2_london, :].topk(10))\n",
    "print(g_adjacency_matrix[g_london, :].topk(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.5233, 0.4914, 0.3599, 0.3028, 0.2941, 0.2929, 0.2885, 0.2346, 0.1975,\n",
      "        0.1929]),\n",
      "indices=tensor([ 7507,  2620,  8806,  4111,  2009,  5511,   718, 12037,  5605,  4790]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0049, 0.4441, 0.3163, 0.2815, 0.2554, 0.2284, 0.2196, 0.2130, 0.2093,\n",
      "        0.1897]),\n",
      "indices=tensor([ 1062, 10871,  1725, 15231,  2813, 13524,   875,  2482, 15989,  2458]))\n"
     ]
    }
   ],
   "source": [
    "print(g2_adjacency_matrix[g2_anger, :].topk(10))\n",
    "print(g_adjacency_matrix[g_anger, :].topk(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wedding\n",
    "print(g2_adjacency_matrix[g2_wedding_1, :].topk(10))\n",
    "print(g_adjacency_matrix[g_wedding_1, :].topk(10))\n",
    "print(g2_adjacency_matrix[g2_wedding_2, :].topk(10))\n",
    "print(g_adjacency_matrix[g_wedding_2, :].topk(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
