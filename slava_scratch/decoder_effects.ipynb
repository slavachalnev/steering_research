{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at what happens to the encoder when we inject a decoder vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fcf716d8400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import einops\n",
    "\n",
    "from sae_lens import SAE\n",
    "# from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "# from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "from steering.evals_utils import evaluate_completions, multi_criterion_evaluation\n",
    "from steering.utils import normalise_decoder\n",
    "from steering.patch import generate, scores_2d, patch_resid\n",
    "\n",
    "# from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3498e6618e184d03b4839ac0e758deac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp6 = \"blocks.6.hook_resid_post\"\n",
    "\n",
    "sae6, _, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = hp6, # won't always be a hook point\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "sae6 = sae6.to(device)\n",
    "normalise_decoder(sae6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intelligence = sae6.W_dec[10351]   # intelligence and genius\n",
    "writing = sae6.W_dec[1058]  # writing\n",
    "anger = sae6.W_dec[1062]  # anger\n",
    "london = sae6.W_dec[10138]  # London\n",
    "wedding = sae6.W_dec[8406]  # wedding\n",
    "broad_wedding = sae6.W_dec[2378] # broad wedding\n",
    "\n",
    "broad_poetry = sae6.W_dec[11067]  # broad poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "steer = broad_wedding\n",
    "scale = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "data = load_dataset(\"NeelNanda/c4-code-20k\", split=\"train\")\n",
    "tokenized_data = tutils.tokenize_and_concatenate(data, model.tokenizer, max_length=32)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "loader = DataLoader(tokenized_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "\n",
    "diffs = torch.zeros(sae6.cfg.d_sae, device=sae6.W_dec.device)\n",
    "\n",
    "for batch_idx, batch in enumerate(loader):\n",
    "\n",
    "    _, acts = model.run_with_cache(batch['tokens'], names_filter=hp6)\n",
    "    acts = acts[hp6]\n",
    "    acts = acts.reshape(-1, acts.shape[-1]) \n",
    "\n",
    "    pre_distribution = sae6.encode(acts)\n",
    "    post_distribution = sae6.encode(acts + steer*scale)\n",
    "\n",
    "    diff = post_distribution - pre_distribution\n",
    "    diffs += diff.sum(dim=0)\n",
    "\n",
    "    if batch_idx >= n_steps - 1:\n",
    "        break\n",
    "\n",
    "diffs /= (n_steps*32*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2378,  4115,  1302, 13791,   722, 12110,  7215,  8406, 13882,  9367],\n",
      "       device='cuda:0')\n",
      "tensor([92.2852, 11.4228,  9.0107,  8.4798,  6.7220,  6.1105,  5.6003,  5.4764,\n",
      "         5.0357,  4.9481], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "top_v, top_i = torch.topk(diffs, 10, dim=-1)\n",
    "print(top_i)\n",
    "print(top_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11631, 15417, 15481, 11683,  4857,  3869, 14173,  2813,  7690, 12661],\n",
      "       device='cuda:0')\n",
      "tensor([2.7186, 1.8626, 1.5036, 0.8218, 0.7397, 0.5358, 0.4955, 0.4613, 0.4226,\n",
      "        0.4091], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "bottom_v, bottom_i = torch.topk(-diffs, 10, dim=-1)\n",
    "print(bottom_i)\n",
    "print(bottom_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I think a lot of you have heard this before and its no secret! but my heart honestly just loves the',\n",
       " 'I think I am SO lucky that our wedding day was a day we got to be able to have- a',\n",
       " 'I think you have a point that you should add into your photos. A sweet vintage or modern design is a',\n",
       " \"I think it's a beautiful classic and a must do! It was a picture on their Pinterest board.\",\n",
       " 'I think this is one word that can be described perfectly by any word and that is what we all want.',\n",
       " 'I think that the new trend is a \"no photo booth! \" The photos you get is an out side',\n",
       " 'I think I have always love it when I had a picture of my picture in my instagram album. I love',\n",
       " 'I think this is an absolutely stunning wedding day at <strong><em>the talented couple blog</em></strong>, all about',\n",
       " \"I think it's absolutely adorable.\\n\\nYou girls at your new location and 1 hour! This is\",\n",
       " 'I think this is an amazing quote! I always love the moments when your wedding day comes but I have one',\n",
       " 'I think this is a great idea! I was obsessed with it. My wedding was so casual! So I',\n",
       " 'I think people will fall into a beautiful story that they can’t live for! Love & Style is where',\n",
       " 'I think this is one of my favorite parts of the wedding day! It should always be captured! But it',\n",
       " 'I think that every boy and girl photographer should spend less than a day of time so that they can have.',\n",
       " 'I think we should just do it!! A great big photo collage in all the images for our scrapbook photos!!!',\n",
       " 'I think there is an amazing selection of photographs on this site. I have to admit the photos are beautiful and',\n",
       " 'I think it is pretty safe to do this even if it means mixing up your wedding timeline! We shoot a',\n",
       " 'I think it is the season in which you can create a lasting memory of your wedding day and all the images',\n",
       " 'I think the number one thing I remember about my wedding day is our time I was so excited about, but',\n",
       " \"I think that's a fun idea!!! I love it!!!!!\\n\\nI love how this is something very DIY\",\n",
       " 'I think the following is true:\\nThe first photo on our wedding day has a touch of “unposed',\n",
       " 'I think it was so important!  It was a fun way to capture the moment and it showed. We',\n",
       " 'I think you got me!!! I am the type of couple with a last name why, an image of a',\n",
       " 'I think how a wedding looks is what your families would do...and in case this is it! If you',\n",
       " 'I think this is very cute idea, which is perfect of the wedding day.\\n\\nWith this blog, your',\n",
       " 'I think we all need a wedding moment to stand out for an amazing photo, and it needs to be epic',\n",
       " 'I think a lot of brides should see the pictures of an oversized collection of images, and all I wanted.',\n",
       " 'I think we have to plan about 3 hours to capture this wedding video footage and the beautiful photo-worthy',\n",
       " 'I think it is absolutely crucial to hire a professional photographer behind-the-scenes time. I was beyond excited',\n",
       " 'I think it’s really important to spend some time at a special time, so you can have a break',\n",
       " 'I think this dress was a super bright and fun addition to their list: wedding paper moments which were added into',\n",
       " 'I think it is pretty important to have fun as an opportunity for our wedding day, and we don’s']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = generate(model, hooks=[(hp6, partial(patch_resid, steering=steer, scale=80))], prompt='I think', n_samples=32, batch_size=32)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
