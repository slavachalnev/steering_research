{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f655ef0a020>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sae_lens import SAE\n",
    "# from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "# from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import normalise_decoder\n",
    "from steering.patch import generate, scores_2d, patch_resid\n",
    "\n",
    "# from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76e7ce9e6ff41f198376f9f826d81b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp6 = \"blocks.6.hook_resid_post\"\n",
    "\n",
    "sae6, _, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = hp6, # won't always be a hook point\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "sae6 = sae6.to(device)\n",
    "normalise_decoder(sae6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligence = sae6.W_dec[10351]   # intelligence and genius\n",
    "writing = sae6.W_dec[1058]  # writing\n",
    "anger = sae6.W_dec[1062]  # anger\n",
    "london = sae6.W_dec[10138]  # London\n",
    "wedding = sae6.W_dec[8406]  # wedding\n",
    "broad_wedding = sae6.W_dec[2378] # broad wedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsteered_texts = generate(model,\n",
    "        hooks=[],\n",
    "        max_new_tokens=25,\n",
    "        prompt=\"I think\",\n",
    "        batch_size=64,\n",
    "        n_samples=4096,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wedding_texts = generate(model,\n",
    "        hooks=[(hp6, partial(patch_resid, steering=wedding, scale=60))],\n",
    "        max_new_tokens=25,\n",
    "        prompt=\"I think\",\n",
    "        batch_size=64,\n",
    "        n_samples=4096,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "london_texts = generate(model,\n",
    "        hooks=[(hp6, partial(patch_resid, steering=london, scale=60))],\n",
    "        max_new_tokens=25,\n",
    "        prompt=\"I think\",\n",
    "        batch_size=64,\n",
    "        n_samples=4096,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I think this is the most beautiful dress you can buy. It has been photographed as a wedding dress but the skirt is a soft material',\n",
       " 'I think about how I live the majority of my life with a different mind to London, at my home of London for the summer of',\n",
       " 'I think you should be able to create an example app with this functionality already.\\n\\n@dmitrivb If we are going to',\n",
       " 'I think this is a very good film adaptation of the book with Paul At Black which I originally read in my late teens to see what',\n",
       " 'I think if this were on the floor I was in the pub in an evening wearing this with a leather jacket. I’m always',\n",
       " 'I think it was in the 40s, or the end of 50s, 70s, and I',\n",
       " 'I think for something to be called “world famous” it has to be really popular all over the world right? If the London Eye',\n",
       " 'I think they would all love your son. They have so many activities! We are not very close to London yet, but we visit',\n",
       " 'I think I have just found what was missing from London, so to speak, from my eyes for a long time. Here you can',\n",
       " 'I think it is worth to go to the airport for the day, but, even, for a short flight or train is fine.',\n",
       " 'I think <strong>M&K</strong> are pretty tough. They were made for the 62mm. And I really like to',\n",
       " 'I think its one of the best films I have ever seen, I just got it 2 days ago. Its great\\n\\nI also',\n",
       " 'I think it’s safe to say that, now that <em>The Amazing</em> <em>Avengers</em> and <em>Iron</em> ',\n",
       " 'I think you are using the <code>[</code> <code>.css</code> and <code>css</code> in your webpack configuration are different.',\n",
       " 'I think our love lives could do with some attention this New Year! Why not treat your loved ones to some gifts for them for Christmas',\n",
       " 'I think this could prove to be a problem for us. We are on our journey now, the first in the world, a London',\n",
       " \"I think this is a commonality among all great women's cricketers. The way to think about this. Is that it'\",\n",
       " 'I think this was from the end of 1967 (and the first half of 1968) or early',\n",
       " \"I think it's a really good thing\\nBut the way a place's designed will make it a good attraction to come to\",\n",
       " 'I think the biggest mistake with the original version of the game is that it was released as a port, not as a full HD release',\n",
       " \"I think we're both a bit new to this stuff, and just going to London for my first visit, but we'd\",\n",
       " 'I think the best answer given here is - the story of the boy is not really a story in itself. A story is a series',\n",
       " \"I think I've got an idea for a new way of managing my social life!\\n\\nA couple of weeks ago I had a\",\n",
       " 'I think we all knew it was coming. It seems the days are numbered, so let me explain. This London 201',\n",
       " 'I think your question is 1) does your local hospital have private facilities? Not sure the answer to 2) Are you an',\n",
       " 'I think that I have a serious problem. I bought a K7 with loads of games on it, but the system now seems to',\n",
       " \"I think I've made it to a city that I never thought I'd see.  I can't quite get here\",\n",
       " 'I think of as a London-based designer, so was surprised to see one of my fellow artists and illustrators, Sophie Hardling',\n",
       " 'I think this is the perfect time to reflect on the state of British pop music. As the Brits prepare to welcome the world’s',\n",
       " \"I think of her as like my little sister, which I am so proud of and it's only been 9 months.\\n\\n\",\n",
       " 'I think i need help setting my house up for a party!\\n\\nHow do i put lights over in an apartment?? or just general',\n",
       " 'I think my family will be the first users for my new London Studio when I moved there.  They are going to London too as',\n",
       " 'I think the \"A\" train\\'s red line, is a symbol of freedom and liberty. That train is iconic. The London',\n",
       " 'I think one of the best places to visit in Malaysia by Bus Tour is Kuala Lumpur. It is the capital of England of South Asia',\n",
       " 'I think this film was the first time an actor of my background (I’m Nigerian) would play a black character (the film',\n",
       " 'I think I’ve found a solution.\\n\\nWhen I first saw the design, I wasn’t happy.  \\n\\nThen I',\n",
       " 'I think we need a new London for once, especially after a year of ‘the lockdown’ I am going to have a summer in',\n",
       " 'I think we can safely assume that the London Transport Underground Underground Underground (the Underground, in general, being a city) is a tourist',\n",
       " \"I think you'll find the following post helpful.\\n\\nIn all fairness to both sides London is the financial capital of the world and\",\n",
       " \"I think this is a really cool concept, but it was the whole thing. I don's think the movie, The Night is\",\n",
       " 'I think I used it a lot, so I probably had something like 30+ users accessing that room in their homes.\\n\\n',\n",
       " 'I think this is only on the \"London\" 2012 one. The other set of London 2012',\n",
       " 'I think this is the most difficult topic ever on here (and most interesting as I had a 12.5, 1',\n",
       " 'I think there are a few different thoughts on this. Most people will say that the only way someone is ever legally blind is if the',\n",
       " \"I think I've been living my life with a very limited perspective. I do the London city life with its congestion and pollution,\",\n",
       " 'I think it is safe to argue that I am a sucker for the Harry Potter series. I used to go to school, and the',\n",
       " 'I think there are two ways to take it. If the driver and everyone else is in London, then pick the tube to London bridge',\n",
       " 'I think the first I heard about them was in the late 90s. They were the first underground rave to do all black',\n",
       " 'I think we can all agree that what we are facing is London 2012 a new season in the fashion month calendar.',\n",
       " \"I think you can buy just the plug. I'd suggest a plumber or a plumber's mate.\\n\\nI had a plumber\",\n",
       " \"I think there could be more games, please\\nit would be amazing :) \\nIs there gonna be a London round? I'\",\n",
       " 'I think I finally found the perfect place for these, my friends! As I have now been in London for 8 years, but',\n",
       " 'I think it’s about, but, but is better by 300 so\\n\\ni’m not saying it’s',\n",
       " 'I think most people don’t understand why I’m so enthusiastic about this place.  At first I expected to spend a day',\n",
       " 'I think we Londoners need a place for a little escape. It can be far from the hustle and bustle and a place of tranquility',\n",
       " \"I think it's ok if it's just an old fashioned idea!\\n\\nFor us, our wedding has a bit of a\",\n",
       " \"I think this is a great movie. I would recommend this to anyone. I watched it with my niece and friends, I'm\",\n",
       " 'I think I will try it out this weekend.\\n\\nI was on line this morning shopping and as usual it had a few new releases',\n",
       " 'I think the only thing that needs to be addressed here is a different language. To the west we have the English name to this \"',\n",
       " 'I think of a place where I could go or move. I could move where I can meet new people. There are lots of cities',\n",
       " 'I think this is a great series! But also London, Rome (too many of them), and Paris. They are fun! Great',\n",
       " 'I think you need to do everything London - Barcelona in one trip. I will never understand this approach. You really need to be in',\n",
       " 'I think a new edition of the HFS (London Symphony Orchestra) has been released for the first time, but its first edition was',\n",
       " \"I think we need more threads with pictures of our home and/or surroundings. I'll start with our bedroom, first\\n\\n(\",\n",
       " 'I think this is just my own little way of sharing my experience with all, as I have not found it in other books. Although',\n",
       " \"I think I'm not really using any proper name for the function on which I need the approximation. So it is like, given\",\n",
       " 'I think it is safe to say that we all love the holiday season! There is always so much to celebrate and we love the opportunity',\n",
       " 'I think the \"real\" answer is you will feel better when you feel better. If the first trimester does mean more sickness for you',\n",
       " \"I think I have two of the best co-workers in the world. They're awesome. I could tell this story a lot\",\n",
       " \"I think it's best to start with some context. I work for a company that has adopted AWS for its back end infrastructure.\",\n",
       " \"I think you could say 'I haven't had lunch yet?' or 'I haven't had lunch yet.', in case you\",\n",
       " \"I think this is the reason you dont see many (if any) of these. It's a terrible way to do business and\",\n",
       " 'I think most people would agree that this past semester was absolutely hell for us high schoolers.  As the time leading up to the',\n",
       " 'I think for 100s of miles from what I read about there was a very small percentage of problems and for 2',\n",
       " 'I think in all of my adult life I have been drawn towards making my own crafts. But I have only made a small part of',\n",
       " 'I think I might have a problem, I think I might be addicted to the internet. If you’re thinking what in the world',\n",
       " \"I think I'd be inclined to go for the smaller motor as the lower cylinder pressure should mean that the bigger one will do less\",\n",
       " \"I think there are a few potential reasons your email isn't receiving emails from the server (or some of them):\\n\\n1)\",\n",
       " \"I think I may have made a thread for this at one point and have since decided to update the thread as I've made a\",\n",
       " 'I think your question is missing.\\n\\nWhat is the volume (L) of the mixture?  \\nGiven volume and density, you',\n",
       " 'I think both these are good points. They highlight how some of these apps rely heavily on the popularity of big stars. However the number',\n",
       " 'I think a lot of us are like Peter. We look back on that time in our lives and we think there were many things we',\n",
       " 'I think that it’s probably not such a common question.\\n\\n<strong>What can be better for a holiday? A city or an',\n",
       " 'I think there needs to be a difference between a “hard” word and an “easy” word.\\n\\nSometimes, I don’',\n",
       " 'I think I may have found my next favorite flavor, and not even in my home country of Canada. (Well…if you count',\n",
       " 'I think this is the best movie I have seen in a long long time. And that is saying something considering the previous two words are',\n",
       " \"I think you are going to have to set the values as attributes of the object in the XML.  You can't get a\",\n",
       " 'I think I may be the first person in the history of the internet to write about their time working at J.D. Power and',\n",
       " 'I think one of the biggest misconceptions I’ve heard is <em>“You don’t have to have the original box to sell',\n",
       " 'I think we all know by now that we are facing something unprecedented in history, in terms of a natural catastrophe. To try to make',\n",
       " \"I think it's very interesting and unique. I bought this for my sister, I think she'll love it.\\nMy\",\n",
       " \"I think I'm gonna change the interior of my truck and have been using this forum for advice on this and other related topics.\",\n",
       " \"I think the big problem is she has two personalities that need to be dealt with.\\nIt's not the personality but the fear\",\n",
       " 'I think it may be an issue with your browser. Please see if Chrome or Safari works.\\n\\nYou may receive an error when a',\n",
       " 'I think the thing that makes these films so interesting is the people they are about; some of them are famous, some are not.',\n",
       " 'I think we need to talk about how to improve communication, so we see a little more of what our partners are doing and feel more',\n",
       " \"I think it's about the size of a pencil, but I can't remember where I saw it. That's the\",\n",
       " 'I think I have always had a passion for building stuff. As a kid, I would watch my dad build little wooden homes for his',\n",
       " \"I think I have been reading the wrong kind of stuff.  My wife says I am reading too many blogs.  I don'\",\n",
       " 'I think of him as Father.\\n\\nAfter going to the hospital as a boy, he left my parents to pursue his career in Medicine']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_texts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_feature_freqs(texts: list[str], model: HookedTransformer, sae: SAE, hook_point: str):\n",
    "    all_sae_acts = torch.zeros(sae.cfg.d_sae, device=sae.W_enc.device)\n",
    "    count = 0\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        _, acts = model.run_with_cache(text, names_filter=hook_point)\n",
    "        acts = acts[hook_point]\n",
    "\n",
    "        for batch in acts:\n",
    "            sae_acts = sae.encode(batch)\n",
    "            all_sae_acts += sae_acts.sum(dim=0)\n",
    "            count += acts.shape[0]\n",
    "    return all_sae_acts / count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_logit_distribution(texts: list[str], model: HookedTransformer):\n",
    "    logit_distribution = torch.zeros(model.cfg.d_vocab, device=model.W_E.device)\n",
    "    count = 0\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        logits = model.forward(text, return_type='logits') #shape is (batch_size, seq_len, d_vocab)\n",
    "\n",
    "        logit_distribution += logits.sum(dim=(0, 1))\n",
    "        count += logits.shape[0] * logits.shape[1]\n",
    "\n",
    "    return logit_distribution / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [03:49<00:00, 17.82it/s]\n"
     ]
    }
   ],
   "source": [
    "unsteered_freqs = get_feature_freqs(unsteered_texts, model, sae6, hp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [03:50<00:00, 17.81it/s]\n",
      "100%|██████████| 4096/4096 [03:51<00:00, 17.73it/s]\n"
     ]
    }
   ],
   "source": [
    "wedding_freqs = get_feature_freqs(wedding_texts, model, sae6, hp6)\n",
    "london_freqs = get_feature_freqs(london_texts, model, sae6, hp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2378,  8406, 13416, 15803, 12360,  2348,  6355,  7775,  1693,  5002],\n",
      "       device='cuda:0')\n",
      "tensor([1.2617, 1.1150, 0.7704, 0.6828, 0.6228, 0.5884, 0.5829, 0.5460, 0.5299,\n",
      "        0.5272], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w_diff = wedding_freqs - unsteered_freqs\n",
    "top_v, top_i = torch.topk(w_diff, 10, dim=-1)\n",
    "print(top_i)\n",
    "print(top_v)\n",
    "\n",
    "# print('bottom')\n",
    "# bottom_v, bottom_i = torch.topk(-w_diff, 10, dim=-1)\n",
    "# print(bottom_i)\n",
    "# print(bottom_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7775, 11851,  2813, 15831, 10138,   628, 10189,  6125, 16027, 15803],\n",
      "       device='cuda:0')\n",
      "tensor([0.9190, 0.9004, 0.6796, 0.6154, 0.6036, 0.5798, 0.5624, 0.5493, 0.5294,\n",
      "        0.5090], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "london_diff = london_freqs - unsteered_freqs\n",
    "top_v, top_i = torch.topk(london_diff, 10, dim=-1)\n",
    "print(top_i)\n",
    "print(top_v)\n",
    "\n",
    "# print('bottom')\n",
    "# bottom_v, bottom_i = torch.topk(-london_diff, 10, dim=-1)\n",
    "# print(bottom_i)\n",
    "# print(bottom_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [03:48<00:00, 17.91it/s]\n",
      "100%|██████████| 4096/4096 [03:48<00:00, 17.92it/s]\n",
      "100%|██████████| 4096/4096 [03:48<00:00, 17.93it/s]\n"
     ]
    }
   ],
   "source": [
    "unsteered_logits = get_logit_distribution(unsteered_texts, model)\n",
    "wedding_logits = get_logit_distribution(wedding_texts, model)\n",
    "london_logits = get_logit_distribution(london_texts, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
