{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f8b94209f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils as tutils\n",
    "from transformer_lens.evals import make_pile_data_loader, evaluate_on_dataset\n",
    "\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sae_lens import SAE\n",
    "# from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "# from sae_lens import SparseAutoencoder, ActivationsStore\n",
    "\n",
    "# from steering.eval_utils import evaluate_completions\n",
    "from steering.utils import normalise_decoder\n",
    "from steering.patch import generate, scores_2d, patch_resid\n",
    "\n",
    "# from sae_vis.data_config_classes import SaeVisConfig\n",
    "# from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a245d1ebce4be7b79a2054a3627af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HookedTransformer.from_pretrained(\"gemma-2b\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp6 = \"blocks.6.hook_resid_post\"\n",
    "\n",
    "sae6, _, _ = SAE.from_pretrained(\n",
    "    release = \"gemma-2b-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = hp6, # won't always be a hook point\n",
    "    device = 'cpu'\n",
    ")\n",
    "\n",
    "sae6 = sae6.to(device)\n",
    "normalise_decoder(sae6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelligence = sae6.W_dec[10351]   # intelligence and genius\n",
    "writing = sae6.W_dec[1058]  # writing\n",
    "anger = sae6.W_dec[1062]  # anger\n",
    "london = sae6.W_dec[10138]  # London\n",
    "wedding = sae6.W_dec[8406]  # wedding\n",
    "broad_wedding = sae6.W_dec[2378] # broad wedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsteered_texts = generate(model,\n",
    "        hooks=[],\n",
    "        max_new_tokens=25,\n",
    "        prompt=\"I think\",\n",
    "        batch_size=64,\n",
    "        n_samples=1024,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wedding_texts = generate(model,\n",
    "        hooks=[(hp6, partial(patch_resid, steering=wedding, scale=60))],\n",
    "        max_new_tokens=25,\n",
    "        prompt=\"I think\",\n",
    "        batch_size=64,\n",
    "        n_samples=1096,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "london_texts = generate(model,\n",
    "        hooks=[(hp6, partial(patch_resid, steering=london, scale=60))],\n",
    "        max_new_tokens=25,\n",
    "        prompt=\"I think\",\n",
    "        batch_size=64,\n",
    "        n_samples=1024,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I think that I'm going to have to get my hands on the 1000 block if/when we ever get\",\n",
       " 'I think the idea from the very beginning was to turn the whole city into a tourist attraction, with attractions in every street and even a',\n",
       " 'I think it would be a good idea to start a series of posts about London in the 1930s. These posts',\n",
       " 'I think he may have been a bit of a con artist but certainly knew his cricket, as he knew the name of almost every player',\n",
       " 'I think the last day of class was held in June of 2016. Now the whole thing was a day away from',\n",
       " 'I think this is an incredible opportunity to talk and compare with other European cities as well. The future should be here and it is just',\n",
       " 'I think most of us have a love/hate/flirting thing going on with our feet all year and when I say London',\n",
       " 'I think the one at the back of the building has the shortest line and you can usually go and catchers without having to do a',\n",
       " 'I think this would be great to see!\\nYeah! They should add back the new style with better text\\n\\nYeah. I would',\n",
       " \"I think this is a mistake of the author of the game. I didn't found such way.\\n\\nI tried searching it in\",\n",
       " 'I think in the old version i remember how to use. Now i tried with new, and could not find it.\\n\\nThis is',\n",
       " 'I think that a great example of cultural identity is from the Great Wall of England, a famous tourist attraction in London made in 2',\n",
       " \"I think this would be useful to have. I've been using a number of different plugins for many years and every one used different\",\n",
       " 'I think we were on the east end of Miami that day, I think our next stop would have been New York City, if I',\n",
       " 'I think I love this movie, so i need to go to one.\\n\\nI agree with you my friend. I love it too',\n",
       " 'I think you mean \"on\" that is one of the four colours in the 1984 Olympics opening ceremony for which the',\n",
       " 'I think you already know that you can watch the <strong>Champions League game</strong> with <strong>Real Madrid vs Tottenham</strong> live. So',\n",
       " \"I think I've just solved how to get the first 52 card deck set, (52 decks of card 1\",\n",
       " \"I think this is one of the best films of 2013.\\n\\nIt's brilliant and brilliant-ish\\n\\nNot\",\n",
       " \"I think the idea of selling for all the London is great I'm getting 300k and the price of all \",\n",
       " \"I think they'll see it as 'what is that you say? - what is it in your dialect?\\nWell it'\",\n",
       " 'I think it would be a good idea for people to start buying it, just imagine I could do the same with my own country...',\n",
       " 'I think, just to add to your question above - we moved to London a couple of years ago.  My husband and I are',\n",
       " \"I think this is probably the 4th thread on this topic.\\n\\nI'm looking at buying a small flat in one central\",\n",
       " 'I think this is a very interesting project and have been following it, although not in great detail. I visited at the start of the',\n",
       " 'I think I’m going to be in town the morning of Dec 16-17 and will be in the Richmond area',\n",
       " 'I think I might be missing something here…\\n\\nThis is a video review of the new F-III range which comes with an ',\n",
       " 'I think I love you…\\n\\nIt’s been two years since the start of February 2017. I’m',\n",
       " \"I think I've lost my password, how do I reset?\\nIf you don't use too much the London 1\",\n",
       " 'I think the idea of setting up a private office is the best way to go for most businesses. It gives access to capital, as',\n",
       " 'I think it seems, to me, like the \"good\" guys and \"bad\" guys have their own identities. London has its',\n",
       " 'I think it would be great to see this too.\\n\\nI feel like this has to be a standard feature for 201',\n",
       " 'I think the only people really feeling the effects of this weekend will be those who missed the London 2017 Games. I',\n",
       " 'I think i need to make it a point to use the London tube for at least a day… not just on a working day,',\n",
       " 'I think that many people do not realise just how serious this countrywide problem is especially as at the end of last month I travelled by',\n",
       " \"I think I would use these and other places for my next adventure. The food is amazing. Everything I've tried has been great\",\n",
       " 'I think she\\'s fine, her clothes were a pretty good fit but I\\'m not seeing a 40\" chest size',\n",
       " \"I think it's worth considering what to pack for Italy on a hot day and all the sights and attractions. How To London is\",\n",
       " 'I think it would be a good idea for all to stop their car at a red traffic light for a while to see what is happening',\n",
       " 'I think this is a great idea but if you use this product you get to have a free shipping which is not on the original order',\n",
       " 'I think my mom would kill me if I ever put a piece of cheese and ham in my mouth lol. London\\n\\nWhat’s',\n",
       " 'I think I’m starting to see a market for this now. I’ve read a couple of articles about it, where there',\n",
       " \"I think if she was really doing it again I think it's the most boring of boring thing.\\n\\nI thought that was the\",\n",
       " 'I think that is just how the calendar works.\\n\\nHi, sorry I have to ask here because, I had the same problem on',\n",
       " 'I think my parents have to pay $85 a year for a \"city\" membership so if she’s going to run from',\n",
       " 'I think this is more of a question for the history or politics but I would need a bit of help there, or maybe I can',\n",
       " \"I think it's a perfect film, I had the same problem for some times and I really loved this one\\n\\nWell is a\",\n",
       " 'I think.\\n\\nIf there is any more to add please add. \\n\\nPlease add more <b>\"</b> <strong>I\\'',\n",
       " 'I think the problem is in the template (probably) <code>_layout.cshtml</code> - where the layout is specified - and the',\n",
       " \"I think that will be fine, especially if it’s going in a high-traffic area.\\n\\nI'm London based,\",\n",
       " 'I think I’ve covered a bit more of the London scene the past few months than perhaps anywhere before. Most of my trips are',\n",
       " 'I think that is the most disappointing piece of news all fall... I could not imagine going to get a piece of cheese.\\n\\nIt',\n",
       " 'I think most of us know about the <strong>London Fog,</strong> the one you eat for your sandwich, or, at this level',\n",
       " 'I think my best guess would be this...\\nI am currently reading The Book of Dust trilogy.\\n\\nI live in London and work',\n",
       " \"I think it's the number plate on the back. I'm not on here often - maybe, just maybe, we were\",\n",
       " 'I think I would also add The Underground Club, as one of the most important institutions in 2034. It seems they',\n",
       " 'I think you should contact the Royal Club. They might have this type of set-up when you need it. They will do the',\n",
       " 'I think one of the main things that sets us apart from the rest of the world is the number of high street retail outlets. With',\n",
       " 'I think you have something in your mouth. I also think some of my friends will make me see someone the same way. I know',\n",
       " 'I think this sounds like a great idea. However, I think that even at peak rush, like 8-9 it would be',\n",
       " 'I think the original plan had been for someone like you, working in a London fashion office with contacts in the street market to find the',\n",
       " \"I think it's so easy to just give up. Even after a week of travel, the sun is just starting to get up\",\n",
       " 'I think my Londoners (and many people I talk to too) have a strong opinion about which area best suits them - and I',\n",
       " 'I think that I speak a lot about the fact I’m not going to see this season, so I guess I’m gonna',\n",
       " 'I think it was around 1964, I was 12, when at a party of mine my father gave me',\n",
       " \"I think what has happened is, that you don't know what the other party has been up to before hand and I'm\",\n",
       " 'I think I got my answers.\\n\\nI will use a <strong>25mm 90 degree angle,</strong> as it provides',\n",
       " \"I think the 1950s was the beginning of a long period that we're heading into disaster over and over and\",\n",
       " 'I think I\\'ve figured out what happened.\\n\\nI had created a new \"user\" account and associated the new account to my',\n",
       " 'I think you use the option \"Set new name\" or you can use the \"rename\" tool, which is an option from the',\n",
       " 'I think you will start to see the big cities on every major airline as they recover from the pandemic.\\n\\nAnd as for the US',\n",
       " 'I think the original is the best. The new version just seems a bit too complicated for me to enjoy reading. The original book is',\n",
       " 'I think that some of them are just not interested in being in a band and some of them simply do not live in Austin. Of',\n",
       " \"I think to myself, I've seen enough of this world, so I take a walk down the beach.\\n\\n* 1\",\n",
       " 'I think I’ve found a simple and delicious way to finish off a batch of scones, and I may just make it for dinner',\n",
       " 'I think I will go for a 3d print.\\n\\nThe model was too big to fit in my 3d printing machine',\n",
       " 'I think that this is a very interesting question. I have been wondering the same thing myself for some time. What I have come up',\n",
       " \"I think the point you're trying to make is to think logically in a way that your parents can understand. They're not\",\n",
       " 'I think they mean the ones that are from 2 to 6 then 8. 9 would probably not make sense unless its',\n",
       " 'I think this is also a bug. In both the 1.13.2 snapshot and the pre-release 2.',\n",
       " 'I think I finally figured it out for you. If you look in your console to the right of the search bar (next to the',\n",
       " 'I think the first thing to consider before you do a 5K challenge is that the body can do lots of different physical activities and',\n",
       " \"I think you've run into a bit of luck on the part of the 2006s. You found a great\",\n",
       " \"I think it's very hard. I think you need to be pretty clear on your requirements (do you want to hire your own\",\n",
       " 'I think we are all looking forward to what 2023 has to offer. We have decided to keep the blog the same',\n",
       " \"I think I've covered this before but was curious if anybody had any specific ideas on what would be the best place to locate the\",\n",
       " 'I think, we are at the final chapter of the last movie. We have gone beyond our dreams and are finally at the point where',\n",
       " 'I think the idea behind the original concept for the <i>Red Alert</i> games was that it would be set in a \"post-',\n",
       " 'I think its really weird. My dad who is a huge 49ers fan and i love reading sports blogs was really mad.',\n",
       " \"I think it's a lot more common than people think - the NHS has a page on it, just in case. I don\",\n",
       " 'I think it looks stunning!\\n\\nI find the whole story interesting. Thanks for telling us about the book. It is nice to find',\n",
       " 'I think the idea of the New Yorker magazine (founded in 1925) is that it is the ultimate modern magazine,',\n",
       " \"I think of myself as a 'maker of things'. I've always enjoyed tinkering, hacking, building and creating. When it came\",\n",
       " \"I think I know what everyone will say. Its an upgrade, it's better than a basic board and better yet...its also\",\n",
       " \"I think, I like the old logo design better. It's the type of old logo that could be used again one day,\",\n",
       " 'I think we’ve all been there…the perfect outfit but without the shoes to match it.\\nThis is where a platform has',\n",
       " 'I think to play the game well, you need both good aim and good reactions: good aim means that, you hit the target,',\n",
       " 'I think the same happens in the following case -\\n\\nIf you open the browser on the computer used to enter the password, <strong>',\n",
       " 'I think you can have many ideas in one piece. You can have a main idea, like a character and you can have supporting ideas',\n",
       " 'I think I already said this, I’m bad.\\nI love this, you know, the old saying; “<em>The']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_texts[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def get_feature_freqs(texts: list[str], model: HookedTransformer, sae: SAE, hook_point: str):\n",
    "#     all_sae_acts = torch.zeros(sae.cfg.d_sae, device=sae.W_enc.device)\n",
    "#     count = 0\n",
    "\n",
    "#     for text in tqdm(texts):\n",
    "#         _, acts = model.run_with_cache(text, names_filter=hook_point)\n",
    "#         acts = acts[hook_point]\n",
    "\n",
    "#         for batch in acts:\n",
    "#             sae_acts = sae.encode(batch)\n",
    "#             all_sae_acts += sae_acts.sum(dim=0)\n",
    "#             count += acts.shape[0]\n",
    "#     return all_sae_acts / count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_feature_freqs(texts: list[str], model: HookedTransformer, sae: SAE, hook_point: str):\n",
    "    all_sae_acts = torch.zeros(sae.cfg.d_sae, device=sae.W_enc.device)\n",
    "    count = 0\n",
    "    for text in tqdm(texts):\n",
    "        _, acts = model.run_with_cache(text, names_filter=hook_point)\n",
    "        acts = acts[hook_point]\n",
    "        for batch in acts:\n",
    "            sae_acts = sae.encode(batch)\n",
    "            all_sae_acts += (sae_acts > 10).sum(dim=0)  # Count non-zero elements\n",
    "            count += acts.shape[0]\n",
    "    return all_sae_acts / count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_logit_distribution(texts: list[str], model: HookedTransformer):\n",
    "    logit_distribution = torch.zeros(model.cfg.d_vocab, device=model.W_E.device)\n",
    "    count = 0\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "        logits = model.forward(text, return_type='logits') #shape is (batch_size, seq_len, d_vocab)\n",
    "\n",
    "        logit_distribution += logits.sum(dim=(0, 1))\n",
    "        count += logits.shape[0] * logits.shape[1]\n",
    "\n",
    "    return logit_distribution / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [03:49<00:00, 17.82it/s]\n"
     ]
    }
   ],
   "source": [
    "wedding_freqs = get_feature_freqs(wedding_texts, model, sae6, hp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1024 [00:00<00:56, 17.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:57<00:00, 17.82it/s]\n",
      "100%|██████████| 1024/1024 [00:57<00:00, 17.88it/s]\n"
     ]
    }
   ],
   "source": [
    "unsteered_freqs = get_feature_freqs(unsteered_texts, model, sae6, hp6)\n",
    "# wedding_freqs = get_feature_freqs(wedding_texts, model, sae6, hp6)\n",
    "london_freqs = get_feature_freqs(london_texts, model, sae6, hp6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  613, 15231, 13416, 15208,  1481,  8663,  2378,  9655,  3921,  9699],\n",
      "       device='cuda:0')\n",
      "tensor([0.4387, 0.4155, 0.2979, 0.2185, 0.2144, 0.2124, 0.1719, 0.1604, 0.1545,\n",
      "        0.1533], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "w_diff = wedding_freqs - unsteered_freqs\n",
    "top_v, top_i = torch.topk(w_diff, 10, dim=-1)\n",
    "print(top_i)\n",
    "print(top_v)\n",
    "\n",
    "# print('bottom')\n",
    "# bottom_v, bottom_i = torch.topk(-w_diff, 10, dim=-1)\n",
    "# print(bottom_i)\n",
    "# print(bottom_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15231,   613, 11803,  5002, 10655, 13903, 14812,  6134, 11575,  5108],\n",
      "       device='cuda:0')\n",
      "tensor([0.6104, 0.5664, 0.5068, 0.3008, 0.2666, 0.2393, 0.2354, 0.2266, 0.2158,\n",
      "        0.2139], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "london_diff = london_freqs - unsteered_freqs\n",
    "top_v, top_i = torch.topk(london_diff, 10, dim=-1)\n",
    "print(top_i)\n",
    "print(top_v)\n",
    "\n",
    "# print('bottom')\n",
    "# bottom_v, bottom_i = torch.topk(-london_diff, 10, dim=-1)\n",
    "# print(bottom_i)\n",
    "# print(bottom_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsteered_logits = get_logit_distribution(unsteered_texts, model)\n",
    "# wedding_logits = get_logit_distribution(wedding_texts, model)\n",
    "# london_logits = get_logit_distribution(london_texts, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# london_logit_diff = london_logits - unsteered_logits\n",
    "# top_v, top_i = torch.topk(london_logit_diff, 10, dim=-1)\n",
    "# print(top_i)\n",
    "# print(model.to_str_tokens(top_i))\n",
    "# print(top_v)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wedding_logit_diff = wedding_logits - unsteered_logits\n",
    "# top_v, top_i = torch.topk(wedding_logit_diff, 10, dim=-1)\n",
    "# print(top_i)\n",
    "# print(model.to_str_tokens(top_i))\n",
    "# print(top_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
